# @package _global_

training:
  trn_path: "data/sample_100.lmdb"
  val_path: "data/sample_100.lmdb"
  bz: 3
  bz_val: 3
  num_workers: 2  

# Pytorch Lightning Trainer configuration
pltrainer:
  # accelerator: "cpu"
  max_epochs: 3
  limit_train_batches: 3
  limit_val_batches: 3

# model:
#   do_eigvec_2: false

use_wandb: false

# no need to resume or save checkpoints
ckpt_resume_auto: false
ckpt_do_save: false
ckpt_trainer_path: null

experiment_name: "debug"
