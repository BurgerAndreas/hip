# @package _global_


# Optimizer configuration
optimizer:
  optimizer: "adamw" # adamw or muon, but muon has only ~20 2d params 
  lr: 3e-4  
  # betas: [0.8, 0.95] # [0.9, 0.999], [0.9, 0.95], [0.8, 0.95]
  betas: [0.9, 0.999]
  beta1: null
  beta2: null
  weight_decay: 0 # 0.01, 1e-5
  amsgrad: true # true

training:
  bz: 64
  bz_val: 64
  num_workers: 2 # 48

  # horm used: loss = floss * 100 + eloss * 4 + hessian_loss * 4
  hessian_loss_weight: 4.0
  energy_loss_weight: 4.0
  force_loss_weight: 100.0
  hessian_loss_type: "mae"

  ad_hessian: true
  hvps: 2

  gradient_clip_val: 0.1

