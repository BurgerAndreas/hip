# @package _global_

model:
  alpha_drop:               0.0         # [0.0, 0.1]
  drop_path_rate:           0.0         # [0.0, 0.05]
  proj_drop:                0.0

training:
  hessian_loss_type: "mae"
  eigen_loss:
    k: 8
    alpha: 1.0

optimizer:
  # muon
  optimizer: "muon"
  lr_muon: 1e-3
  weight_decay_muon: 0.001
  # adamw
  amsgrad: False
  beta1: 0.965
  beta2: 0.965
  lr: 0.00044
  weight_decay: 2e-05

pltrainer:
  gradient_clip_algorithm: norm
  gradient_clip_val: 7
  