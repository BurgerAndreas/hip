program: scripts/train.py
project: hip
method: bayes
metric:
  name: val-totloss
  goal: minimize
parameters:
  optimizer.lr:
    distribution: log_uniform_values
    min: 1e-5
    max: 3e-4
  optimizer.weight_decay:
    distribution: log_uniform_values
    min: 1e-6
    max: 1e-2
  optimizer.amsgrad:
    distribution: categorical
    values: [true, false]
  optimizer.beta1:
    distribution: log_uniform_values
    min: 0.8
    max: 0.999
  optimizer.beta2:
    distribution: log_uniform_values
    min: 0.8
    max: 0.999
  training.hessian_loss_weight:
    distribution: log_uniform_values
    min: 1.0
    max: 50.0
  # training.energy_loss_weight:
  #   distribution: log_uniform_values
  #   min: 1.0
  #   max: 50.0
  training.force_loss_weight:
    distribution: log_uniform_values
    min: 1.0
    max: 50.0
  model.max_radius:
    values: [6, 12]
  model.cutoff_hessian:
    values: [6, 12, 100]
  # training.eigen_loss.alpha:
  #   distribution: uniform
  #   min: 0.0
  #   max: 1.0
  # training.bz:
  #   values: [64, 96, 128]
  # pltrainer.devices:
  #   value: 1
command:
  - ${env}
  - uv
  - run
  - ${program}
  - optimizer.lr=${optimizer.lr}
  - optimizer.weight_decay=${optimizer.weight_decay}
  - optimizer.amsgrad=${optimizer.amsgrad}
  - optimizer.betas=[${optimizer.beta1}, ${optimizer.beta2}]
  # - training.energy_loss_weight=${training.energy_loss_weight}
  - training.force_loss_weight=${training.force_loss_weight}
  - training.hessian_loss_weight=${training.hessian_loss_weight}
  # - training.eigen_loss.alpha=${training.eigen_loss.alpha}
  - model.max_radius=${model.max_radius}
  - model.cutoff_hessian=${model.cutoff_hessian}
  - training.bz=64
  - training.bz_val=64
  - ${args}

