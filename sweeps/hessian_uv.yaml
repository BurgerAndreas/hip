program: scripts/train.py
project: hip
method: bayes
metric:
  name: val-totloss
  goal: minimize
parameters:
  optimizer.lr:
    distribution: uniform
    min: 0.00015
    max: 0.0006
  optimizer.weight_decay:
    distribution: uniform
    min: 0.000005
    max: 0.00002
  optimizer.amsgrad:
    distribution: categorical
    values: [true, false]
  optimizer.beta1:
    distribution: log_uniform_values
    min: 0.8
    max: 0.99
  optimizer.beta2:
    distribution: log_uniform_values
    min: 0.8
    max: 0.999
  pltrainer.gradient_clip_algorithm:
    values:
      - norm
      - value
    distribution: categorical
  pltrainer.gradient_clip_val:
    distribution: log_uniform_values
    min: 0.1
    max: 10
  training.hessian_loss_weight:
    distribution: int_uniform
    min: 5
    max: 20
  # training.energy_loss_weight:
  #   distribution: log_uniform_values
  #   min: 1.0
  #   max: 50.0
  training.force_loss_weight:
    distribution: int_uniform
    min: 13
    max: 50
  # model.max_radius:
  #   distribution: int_uniform
  #   min: 5
  #   max: 24
  # model.cutoff_hessian:
  #   distribution: int_uniform
  #   min: 5
  #   max: 100
  # training.eigen_loss.alpha:
  #   distribution: uniform
  #   min: 0.0
  #   max: 1.0
  # training.bz:
  #   values: [64, 96, 128]
  # pltrainer.devices:
  #   value: 1
command:
  - ${env}
  - uv
  - run
  - ${program}
  # fixed
  - training.bz=64
  - training.bz_val=64
  # - model.max_radius=6
  # - model.cutoff_hessian=100
  # our args
  - ${args_no_hyphens}

